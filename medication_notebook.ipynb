{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["J1CTkwp-Bt7z","6TkkYlepBzl3"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZCGi0N6_SLR","executionInfo":{"status":"ok","timestamp":1750607959011,"user_tz":-540,"elapsed":17049,"user":{"displayName":"김세희","userId":"10121931475775017609"}},"outputId":"4a96661b-1043-4f4e-aad3-778642ed508b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install pyngrok streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dH_ZdMBH0ebu","outputId":"c614dfe6-acc2-48df-b73d-a32afd7c22b0","executionInfo":{"status":"ok","timestamp":1750604724763,"user_tz":-540,"elapsed":21294,"user":{"displayName":"김세희","userId":"10121931475775017609"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n","Collecting streamlit\n","  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n","Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 pyngrok-7.2.11 streamlit-1.46.0 watchdog-6.0.0\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","ngrok_token = userdata.get(\"NGROK_API_KEY\")\n","!ngrok config add-authtoken {ngrok_token}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZdPFFvw0iLr","outputId":"d1e34836-d70c-49cf-e99d-f0fddbc465e7","executionInfo":{"status":"ok","timestamp":1750604942371,"user_tz":-540,"elapsed":2189,"user":{"displayName":"김세희","userId":"10121931475775017609"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TLR-mdvlWuKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import subprocess\n","import os\n","from google.colab import userdata\n","import signal\n","import time\n","import streamlit as st\n","import torch\n","import numpy as np\n","from torch import optim\n","from PIL import Image\n","import torch.nn.functional as F\n","import cv2\n","import requests\n","import base64\n","import uuid\n","import re\n","import glob\n","from collections import defaultdict\n","from transformers import CLIPProcessor, CLIPModel\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"],"metadata":{"id":"1BPFHW1NAEJw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CLIP 모델 파인튜닝"],"metadata":{"id":"J1CTkwp-Bt7z"}},{"cell_type":"code","source":["disposal_map = {\n","    \"알약_블리스터팩\": \"겉 포장지(종이 또는 플라스틱 필름)를 제거하고, 플라스틱 블리스터팩은 그대로 의약품 수거함에 버리세요.\",\n","    \"알약_블리스터팩_박스\": \"종이 박스는 분리하여 종이 재활용함에 버리고, 겉 포장지(종이 또는 플라스틱 필름)를 제거한 후 플라스틱 블리스터팩은 의약품 수거함에 버리세요.\",\n","    \"안약\": \"용기 그대로 의약품 수거함에 버리세요. 남은 약액은 그대로 두셔도 됩니다.\",\n","    \"연고\": \"튜브를 완전히 비우고 의약품 수거함에 버리세요.\",\n","    \"유리병\": \"약은 폐의약품 수거함에 버리고, 유리병은 내용물을 완전히 비운 후 깨끗이 헹궈 병류로 분리배출하세요.\",\n","}\n","\n","labels = [\"알약_블리스터팩\", \"알약_블리스터팩_박스\", \"안약\", \"연고\", \"유리병\"]\n","\n","text_descriptions = [\n","    \"pill blister pack with plastic packaging\",\n","    \"pill blister pack in cardboard box\",\n","    \"small eye drop bottle\",\n","    \"ointment tube for skin\",\n","    \"glass bottle for medicine\"\n","]\n","\n","class SimpleMedicineDataset(Dataset):\n","    def __init__(self, data_list, processor):\n","        self.processor = processor\n","        self.data = data_list\n","        print(f\"데이터셋 크기: {len(self.data)}\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        try:\n","            item = self.data[idx]\n","            image = Image.open(item['image_path']).convert('RGB')\n","\n","            return {\n","                'image': image,\n","                'text': item['text'],\n","                'label': item['label']\n","            }\n","\n","        except Exception as e:\n","            print(f\"데이터 로드 오류: {e}\")\n","            return self.__getitem__((idx + 1) % len(self.data))\n","\n","def load_data(data_dir):\n","    all_data = []\n","    existing_labels = []\n","    existing_texts = []\n","    label_mapping = {}\n","\n","    new_label_idx = 0\n","    for original_idx, label_name in enumerate(labels):\n","        folder_path = os.path.join(data_dir, label_name)\n","        if os.path.exists(folder_path):\n","            img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n","            if len(img_files) > 0:\n","                existing_labels.append(label_name)\n","                existing_texts.append(text_descriptions[original_idx])\n","                label_mapping[original_idx] = new_label_idx\n","\n","                # 데이터 로드\n","                for img_file in img_files:\n","                    all_data.append({\n","                        'image_path': os.path.join(folder_path, img_file),\n","                        'label': new_label_idx,\n","                        'text': text_descriptions[original_idx]\n","                    })\n","\n","                new_label_idx += 1\n","\n","    print(f\"총 {len(all_data)}개 데이터 로드됨\")\n","    print(f\"실제 존재하는 클래스: {len(existing_labels)}개\")\n","\n","    for i, label_name in enumerate(existing_labels):\n","        count = sum(1 for item in all_data if item['label'] == i)\n","        print(f\"{label_name}: {count}개\")\n","\n","    if len(all_data) == 0:\n","        return [], [], existing_labels, existing_texts\n","\n","    train_data, test_data = train_test_split(\n","        all_data,\n","        test_size=0.2,\n","        random_state=42,\n","        stratify=[item['label'] for item in all_data]\n","    )\n","\n","    print(f\"학습 데이터: {len(train_data)}개\")\n","    print(f\"테스트 데이터: {len(test_data)}개\")\n","\n","    return train_data, test_data, existing_labels, existing_texts\n","\n","def collate_fn(batch):\n","    images = [item['image'] for item in batch]\n","    texts = [item['text'] for item in batch]\n","    labels = [item['label'] for item in batch]\n","\n","    return {\n","        'images': images,\n","        'texts': texts,\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","def evaluate_model(model, processor, test_data, existing_labels, existing_texts, device, batch_size=4):\n","    print(\"\\n=== 모델 성능 평가 ===\")\n","\n","    test_dataset = SimpleMedicineDataset(test_data, processor)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n","\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            try:\n","                images = batch['images']\n","                texts = batch['texts']\n","                labels = batch['labels']\n","\n","                inputs = processor(\n","                    images=images,\n","                    text=existing_texts,\n","                    return_tensors=\"pt\",\n","                    padding=True,\n","                    truncation=True\n","                )\n","\n","                pixel_values = inputs['pixel_values'].to(device)\n","                input_ids = inputs['input_ids'].to(device)\n","                attention_mask = inputs['attention_mask'].to(device)\n","\n","                outputs = model(\n","                    pixel_values=pixel_values,\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask\n","                )\n","\n","                # 유사도 계산\n","                logits_per_image = outputs.logits_per_image\n","                predictions = torch.argmax(logits_per_image, dim=1)\n","\n","                all_predictions.extend(predictions.cpu().numpy())\n","                all_labels.extend(labels.numpy())\n","\n","            except Exception as e:\n","                print(f\"평가 중 오류: {e}\")\n","                continue\n","\n","    accuracy = accuracy_score(all_labels, all_predictions)\n","\n","    print(f\"전체 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n","\n","    return accuracy, all_predictions, all_labels\n","\n","def train_model(data_dir, save_dir=\"/content/drive/MyDrive/trash_ai/clip_medication_test\", epochs=5, batch_size=2, learning_rate=1e-5):\n","    print(\"=== CLIP 모델 학습 시작 ===\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    train_data, test_data, existing_labels, existing_texts = load_data(data_dir)\n","\n","    if len(train_data) == 0:\n","        print(\"❌ 학습 데이터가 없습니다.\")\n","        return None, None\n","\n","    print(f\"실제 사용될 클래스들: {existing_labels}\")\n","\n","    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n","    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","\n","    model.to(device)\n","\n","    for param in model.parameters():\n","        param.requires_grad = True\n","\n","    train_dataset = SimpleMedicineDataset(train_data, processor)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn)\n","    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    if len(test_data) > 0:\n","        initial_accuracy, _, _ = evaluate_model(model, processor, test_data, existing_labels, existing_texts, device)\n","\n","    model.train()\n","    best_accuracy = 0\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        batch_count = 0\n","\n","        for batch_idx, batch in enumerate(train_loader):\n","            try:\n","                images = batch['images']\n","                texts = batch['texts']\n","                labels = batch['labels'].to(device)\n","\n","                inputs = processor(\n","                    images=images,\n","                    text=texts,\n","                    return_tensors=\"pt\",\n","                    padding=True,\n","                    truncation=True\n","                )\n","\n","                pixel_values = inputs['pixel_values'].to(device)\n","                input_ids = inputs['input_ids'].to(device)\n","                attention_mask = inputs['attention_mask'].to(device)\n","\n","                outputs = model(\n","                    pixel_values=pixel_values,\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    return_loss=True\n","                )\n","\n","                loss = outputs.loss\n","\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                total_loss += loss.item()\n","                batch_count += 1\n","\n","            except Exception as e:\n","                print(f\"배치 처리 오류: {e}\")\n","                continue\n","\n","        if batch_count > 0:\n","            avg_loss = total_loss / batch_count\n","\n","            if len(test_data) > 0:\n","                accuracy, _, _ = evaluate_model(model, processor, test_data, existing_labels, existing_texts, device)\n","\n","                # 최고 성능 모델 저장\n","                if accuracy > best_accuracy:\n","                    best_accuracy = accuracy\n","                    try:\n","                        best_dir = os.path.join(save_dir, \"best\")\n","                        os.makedirs(best_dir, exist_ok=True)\n","                        model.save_pretrained(best_dir)\n","                        processor.save_pretrained(best_dir)\n","\n","                        import json\n","                        label_info = {\n","                            'labels': existing_labels,\n","                            'texts': existing_texts\n","                        }\n","                        with open(os.path.join(best_dir, 'label_info.json'), 'w', encoding='utf-8') as f:\n","                            json.dump(label_info, f, ensure_ascii=False, indent=2)\n","\n","                    except Exception as e:\n","                        print(f\"❌ 최고 성능 모델 저장 실패: {e}\")\n","                model.train()\n","\n","    # 최종 모델 저장\n","    try:\n","        final_dir = os.path.join(save_dir, \"final\")\n","        os.makedirs(final_dir, exist_ok=True)\n","        model.save_pretrained(final_dir)\n","        processor.save_pretrained(final_dir)\n","\n","        import json\n","        label_info = {\n","            'labels': existing_labels,\n","            'texts': existing_texts\n","        }\n","        with open(os.path.join(final_dir, 'label_info.json'), 'w', encoding='utf-8') as f:\n","            json.dump(label_info, f, ensure_ascii=False, indent=2)\n","\n","        print(\"✅ 최종 모델 저장 완료\")\n","    except Exception as e:\n","        print(f\"❌ 최종 모델 저장 실패: {e}\")\n","\n","    if len(test_data) > 0:\n","        print(f\"\\n=== 최종 성능 평가 ===\")\n","        final_accuracy, predictions, true_labels = evaluate_model(model, processor, test_data, existing_labels, existing_texts, device)\n","        print(f\"최고 달성 정확도: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n","\n","    print(\"=== 학습 완료 ===\")\n","    return model, processor\n","\n","if __name__ == \"__main__\":\n","    model, processor = train_model(\"/content/drive/MyDrive/trash_ai/Medicine_data\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Sd1pqXXijZT","executionInfo":{"status":"ok","timestamp":1748626377997,"user_tz":-540,"elapsed":280968,"user":{"displayName":"히힛","userId":"14574132926497786353"}},"outputId":"ae5ccc1d-4818-43b4-93db-abcffec81247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== CLIP 모델 학습 시작 ===\n","총 376개 데이터 로드됨\n","실제 존재하는 클래스: 5개\n","알약_블리스터팩: 99개\n","알약_블리스터팩_박스: 162개\n","안약: 37개\n","연고: 59개\n","유리병: 19개\n","학습 데이터: 300개\n","테스트 데이터: 76개\n","실제 사용될 클래스들: ['알약_블리스터팩', '알약_블리스터팩_박스', '안약', '연고', '유리병']\n","데이터셋 크기: 300\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.5921 (59.21%)\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.9211 (92.11%)\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.8158 (81.58%)\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.9342 (93.42%)\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.9342 (93.42%)\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.9211 (92.11%)\n","✅ 최종 모델 저장 완료\n","\n","=== 최종 성능 평가 ===\n","\n","=== 모델 성능 평가 ===\n","데이터셋 크기: 76\n","전체 정확도: 0.9211 (92.11%)\n","최고 달성 정확도: 0.9342 (93.42%)\n","=== 학습 완료 ===\n"]}]},{"cell_type":"markdown","source":["###CLIP 모델 성능 평가"],"metadata":{"id":"6TkkYlepBzl3"}},{"cell_type":"code","source":["def detailed_evaluate_model(model, processor, test_data, existing_labels, existing_texts, device, batch_size=4):\n","    print(\"최종 모델 성능 평가\")\n","    print(\"=\"*50)\n","\n","    test_dataset = SimpleMedicineDataset(test_data, processor)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn)\n","\n","    model.eval()\n","    all_predictions = []\n","    all_labels = []\n","    class_correct = [0] * len(existing_labels)\n","    class_total = [0] * len(existing_labels)\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            try:\n","                images = batch['images']\n","                texts = batch['texts']\n","                labels = batch['labels']\n","\n","                inputs = processor(\n","                    images=images,\n","                    text=existing_texts,\n","                    return_tensors=\"pt\",\n","                    padding=True,\n","                    truncation=True\n","                )\n","\n","                pixel_values = inputs['pixel_values'].to(device)\n","                input_ids = inputs['input_ids'].to(device)\n","                attention_mask = inputs['attention_mask'].to(device)\n","\n","                outputs = model(\n","                    pixel_values=pixel_values,\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask\n","                )\n","\n","                logits_per_image = outputs.logits_per_image\n","                predictions = torch.argmax(logits_per_image, dim=1)\n","\n","                all_predictions.extend(predictions.cpu().numpy())\n","                all_labels.extend(labels.numpy())\n","\n","                for i, (pred, true) in enumerate(zip(predictions.cpu().numpy(), labels.numpy())):\n","                    class_total[true] += 1\n","                    if pred == true:\n","                        class_correct[true] += 1\n","\n","            except Exception as e:\n","                print(f\"평가 중 오류: {e}\")\n","                continue\n","\n","    overall_accuracy = accuracy_score(all_labels, all_predictions)\n","\n","    precision, recall, f1, support = precision_recall_fscore_support(\n","        all_labels, all_predictions, average=None, zero_division=0\n","    )\n","\n","    avg_precision = np.mean(precision)\n","    avg_recall = np.mean(recall)\n","    avg_f1 = np.mean(f1)\n","\n","    cm = confusion_matrix(all_labels, all_predictions)\n","\n","    print(f\"\\n📊 전체 성능 요약\")\n","    print(f\"{'='*30}\")\n","    print(f\"전체 정확도: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n","    print(f\"평균 Precision: {avg_precision:.4f} ({avg_precision*100:.2f}%)\")\n","    print(f\"평균 Recall: {avg_recall:.4f} ({avg_recall*100:.2f}%)\")\n","    print(f\"평균 F1-Score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n","    print(f\"총 테스트 샘플 수: {len(all_labels)}개\")\n","\n","    return {\n","        'overall_accuracy': overall_accuracy,\n","        'class_accuracies': [class_correct[i] / max(class_total[i], 1) for i in range(len(existing_labels))],\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'support': support,\n","        'confusion_matrix': cm,\n","        'class_correct': class_correct,\n","        'class_total': class_total,\n","        'predictions': all_predictions,\n","        'true_labels': all_labels\n","    }\n","\n","def load_best_model_and_evaluate(model_dir, test_data_dir):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    best_model_path = os.path.join(model_dir, \"best\")\n","\n","    try:\n","        model = CLIPModel.from_pretrained(best_model_path)\n","        processor = CLIPProcessor.from_pretrained(best_model_path)\n","        model.to(device)\n","        print(\"✅ Best 모델 로드 완료\")\n","    except Exception as e:\n","        print(f\"❌ 모델 로드 실패: {e}\")\n","        return None\n","\n","    try:\n","        with open(os.path.join(best_model_path, 'label_info.json'), 'r', encoding='utf-8') as f:\n","            label_info = json.load(f)\n","        existing_labels = label_info['labels']\n","        existing_texts = label_info['texts']\n","        print(f\"✅ 라벨 정보 로드 완료: {len(existing_labels)}개 클래스\")\n","    except Exception as e:\n","        print(f\"❌ 라벨 정보 로드 실패: {e}\")\n","        return None\n","\n","    train_data, test_data, _, _ = load_data(test_data_dir)\n","\n","    if len(test_data) == 0:\n","        print(\"❌ 테스트 데이터가 없습니다.\")\n","        return None\n","\n","    results = detailed_evaluate_model(\n","        model, processor, test_data, existing_labels, existing_texts, device\n","    )\n","\n","    return results\n","\n","# 사용 예시\n","if __name__ == \"__main__\":\n","    # best 모델로 상세 평가 수행\n","    model_dir = \"/content/drive/MyDrive/trash_ai/clip_medication_test\"\n","    test_data_dir = \"/content/drive/MyDrive/trash_ai/Medicine_data\"\n","\n","    results = load_best_model_and_evaluate(model_dir, test_data_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSUixBprBsMT","executionInfo":{"status":"ok","timestamp":1748626917835,"user_tz":-540,"elapsed":5329,"user":{"displayName":"히힛","userId":"14574132926497786353"}},"outputId":"06a2907e-ea4b-493f-f7ac-06a6be126e27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Best 모델 로드 완료\n","✅ 라벨 정보 로드 완료: 5개 클래스\n","총 376개 데이터 로드됨\n","실제 존재하는 클래스: 5개\n","알약_블리스터팩: 99개\n","알약_블리스터팩_박스: 162개\n","안약: 37개\n","연고: 59개\n","유리병: 19개\n","학습 데이터: 300개\n","테스트 데이터: 76개\n","최종 모델 성능 평가\n","==================================================\n","데이터셋 크기: 76\n","\n","📊 전체 성능 요약\n","==============================\n","전체 정확도: 0.9342 (93.42%)\n","평균 Precision: 0.9239 (92.39%)\n","평균 Recall: 0.8339 (83.39%)\n","평균 F1-Score: 0.8286 (82.86%)\n","총 테스트 샘플 수: 76개\n"]}]},{"cell_type":"markdown","source":["###OCR 인식 및 결과 보정"],"metadata":{"id":"jowe-TMbC7uQ"}},{"cell_type":"code","source":["folder_to_label = {\n","    \"알약_블리스터팩\": 0,\n","    \"알약_블리스터팩_박스\": 1,\n","    \"안약\": 2,\n","    \"연고\": 3,\n","    \"유리병\": 4,\n","}\n","\n","medication_keywords = {\n","    \"pill_related\": [\n","        \"캡슐\", \"mg\", \"정\", \"캡\", \"알약\", \"환\", \"tablet\", \"capsule\", \"cap\", \"pill\",\n","        \"Tablet\", \"Capsule\", \"Cap\", \"Pill\", \"TABLET\", \"CAPSULE\", \"CAP\", \"PILL\",\n","        \"MG\", \"mg\", \"Mg\", \"mcg\", \"µg\", \"IU\", \"unit\", \"Units\", \"UNITS\"\n","    ],\n","    \"ointment_related\": [\n","        \"연고\", \"크림\", \"젤\", \"로션\", \"밤\", \"연고제\", \"%\",\n","        \"ointment\", \"cream\", \"gel\", \"lotion\", \"balm\",\n","        \"Ointment\", \"Cream\", \"Gel\", \"Lotion\", \"Balm\",\n","        \"OINTMENT\", \"CREAM\", \"GEL\", \"LOTION\", \"BALM\"\n","    ],\n","    \"eye_drop_related\": [\n","        \"안약\", \"점안액\", \"점안제\", \"eye\", \"drop\", \"drops\",\n","        \"Eye\", \"Drop\", \"Drops\", \"EYE\", \"DROP\", \"DROPS\",\n","        \"ophthalmic\", \"Ophthalmic\", \"OPHTHALMIC\"\n","    ]\n","}\n","\n","def load_model(model_path=\"/content/drive/MyDrive/trash_ai/clip_medication_test/best\"):\n","    \"\"\"모델과 프로세서를 로드하는 함수\"\"\"\n","    print(\"🔄 모델 로딩 중...\")\n","\n","    try:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        model = CLIPModel.from_pretrained(model_path)\n","        processor = CLIPProcessor.from_pretrained(model_path)\n","        model.to(device)\n","\n","        with open(os.path.join(model_path, 'label_info.json'), 'r', encoding='utf-8') as f:\n","            label_info = json.load(f)\n","\n","        print(\"✅ 모델 로딩 완료!\")\n","        print(f\"📋 로드된 클래스: {label_info['labels']}\")\n","        return model, processor, label_info\n","\n","    except Exception as e:\n","        print(f\"❌ 모델 로드 실패: {e}\")\n","        return None, None, None\n","\n","#OCR 텍스트에서 의약품 관련 키워드 분석\n","def analyze_medication_keywords(ocr_text):\n","    if not ocr_text:\n","        return {\"pill\": 0, \"ointment\": 0, \"eye_drop\": 0}, {}\n","\n","    scores = {\n","        \"pill\": 0,\n","        \"ointment\": 0,\n","        \"eye_drop\": 0\n","    }\n","\n","    found_keywords = {\n","        \"pill\": [],\n","        \"ointment\": [],\n","        \"eye_drop\": []\n","    }\n","\n","    for keyword in medication_keywords[\"pill_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"pill\"] += 1\n","            found_keywords[\"pill\"].append(keyword)\n","\n","    for keyword in medication_keywords[\"ointment_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"ointment\"] += 1\n","            found_keywords[\"ointment\"].append(keyword)\n","\n","    for keyword in medication_keywords[\"eye_drop_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"eye_drop\"] += 1\n","            found_keywords[\"eye_drop\"].append(keyword)\n","    return scores, found_keywords\n","\n","#키워드 점수를 기반으로 CLIP 예측 조정\n","def adjust_clip_predictions(logits, keyword_scores, boost_factor=0.15):\n","\n","    adjusted_logits = logits.clone()\n","\n","    label_keyword_mapping = {\n","        0: \"pill\",      # 알약_블리스터팩\n","        1: \"pill\",      # 알약_블리스터팩_박스\n","        2: \"eye_drop\",  # 안약\n","        3: \"ointment\",  # 연고\n","        4: \"pill\",\n","    }\n","\n","    adjustments = {}\n","    for label_idx, keyword_type in label_keyword_mapping.items():\n","        if keyword_scores[keyword_type] > 0:\n","            # 키워드 점수에 비례해서 logit 값 증가\n","            boost = boost_factor * keyword_scores[keyword_type]\n","            adjusted_logits[0][label_idx] += boost\n","            adjustments[labels[label_idx]] = boost\n","            print(f\"라벨 {labels[label_idx]} 점수 증가: +{boost:.3f} (키워드: {keyword_type}, 개수: {keyword_scores[keyword_type]})\")\n","\n","    return adjusted_logits, adjustments\n","\n","#OCR을 위한 이미지 전처리 개선\n","def preprocess_image_for_ocr(image):\n","    try:\n","        img_array = np.array(image)\n","\n","        if len(img_array.shape) == 3:\n","            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n","        else:\n","            img_bgr = img_array\n","\n","        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","        denoised = cv2.medianBlur(gray, 3)\n","        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","        enhanced = clahe.apply(denoised)\n","        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)\n","        binary_inv = cv2.adaptiveThreshold(\n","            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n","        )\n","        kernel = np.ones((1, 1), np.uint8)\n","        processed = cv2.morphologyEx(binary_inv, cv2.MORPH_CLOSE, kernel)\n","\n","        result_image = Image.fromarray(processed)\n","\n","        return result_image\n","\n","    except Exception as e:\n","        print(f\"이미지 전처리 오류: {e}\")\n","        return image\n","\n","def extract_text_from_image_with_clova(image_path: str):\n","    secret_key = userdata.get(\"OCR_CLOVA\")\n","    api_url = \"https://s79a9gvq9a.apigw.ntruss.com/custom/v1/42492/9274a7c96357207aa7e436c070ceba3fecf0b7f91679a2a8f72283f165493853/general\"\n","\n","    file_size = os.path.getsize(image_path)\n","    if file_size > 5 * 1024 * 1024:  # 5MB\n","        print(\"⚠️ 파일 크기가 5MB를 초과합니다.\")\n","\n","    with open(image_path, \"rb\") as f:\n","        image_data = base64.b64encode(f.read()).decode()\n","\n","    headers = {\n","        \"X-OCR-SECRET\": secret_key,\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","    payload = {\n","        \"version\": \"V2\",\n","        \"requestId\": str(uuid.uuid4()),\n","        \"timestamp\": int(time.time() * 1000),\n","        \"images\": [{\n","            \"name\": \"temp\",\n","            \"format\": \"jpg\",\n","            \"data\": image_data\n","        }]\n","    }\n","\n","    try:\n","        response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=30)\n","        result = response.json()\n","\n","        first_image = result[\"images\"][0]\n","        fields = first_image[\"fields\"]\n","        texts = []\n","\n","        for i, field in enumerate(fields):\n","            if \"inferText\" in field and field[\"inferText\"]:\n","                text = field[\"inferText\"]\n","                texts.append(text)\n","                confidence = field.get(\"inferConfidence\", \"N/A\")\n","\n","        if not texts:\n","            return \"\", 0.0\n","\n","        extracted_text = \" \".join(texts)\n","        return extracted_text, confidence\n","\n","    except Exception as e:\n","        print(f\"❌ OCR API 호출 오류: {e}\")\n","        return \"\", 0.0\n","\n","def classify_and_dispose(image_path: str, model_clip, processor_clip):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    image = Image.open(image_path).convert(\"RGB\")\n","\n","    processed_image = preprocess_image_for_ocr(image)\n","    temp_path = \"temp_processed.png\"\n","    processed_image.save(temp_path)\n","\n","    # OCR로 텍스트 추출\n","    ocr_text, ocr_confidence = extract_text_from_image_with_clova(temp_path)\n","    if ocr_text is None:\n","        ocr_text = \"\"\n","\n","    # 키워드 분석\n","    keyword_scores, found_keywords = analyze_medication_keywords(ocr_text)\n","\n","    # CLIP 모델로 분류\n","    inputs = processor_clip(text=text_descriptions, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model_clip(**inputs)\n","\n","    original_logits = outputs.logits_per_image\n","    adjusted_logits, logit_adjustments = adjust_clip_predictions(original_logits, keyword_scores)\n","\n","    original_probs = original_logits.softmax(dim=1)\n","    adjusted_probs = adjusted_logits.softmax(dim=1)\n","\n","    original_predicted_idx = torch.argmax(original_probs, dim=1).item()\n","    original_predicted_label = labels[original_predicted_idx]\n","    original_confidence = torch.max(original_probs).item()\n","\n","    # 조정된 예측\n","    predicted_idx = torch.argmax(adjusted_probs, dim=1).item()\n","    predicted_label = labels[predicted_idx]\n","    confidence = torch.max(adjusted_probs).item()\n","\n","    # OCR 기반 추가 보정\n","    final_label = predicted_label\n","    ocr_correction_applied = False\n","\n","    if keyword_scores[\"ointment\"] >= 1 and predicted_label != \"연고\":\n","        if confidence < 0.7:\n","            final_label = \"연고\"\n","            confidence = min(confidence + 0.15, 0.95)\n","            ocr_correction_applied = True\n","\n","    if keyword_scores[\"eye_drop\"] >= 1 and predicted_label != \"안약\":\n","        if confidence < 0.7:\n","            final_label = \"안약\"\n","            confidence = min(confidence + 0.15, 0.95)\n","            ocr_correction_applied = True\n","\n","    context = disposal_map.get(final_label, \"종류에 따라 적절한 방법으로 의약품 수거함에 버리세요.\")\n","\n","    return {\n","        \"final_label\": final_label,\n","        \"disposal_context\": context,\n","        \"final_confidence\": confidence,\n","        \"ocr_text\": ocr_text,\n","        \"ocr_confidence\" : ocr_confidence,\n","        \"original_clip_label\": original_predicted_label,\n","        \"original_clip_confidence\": original_confidence,\n","        \"adjusted_clip_label\": predicted_label,\n","        \"adjusted_clip_confidence\": torch.max(adjusted_probs).item(),\n","        \"keyword_scores\": keyword_scores,\n","        \"found_keywords\": found_keywords,\n","        \"logit_adjustments\": logit_adjustments,\n","        \"ocr_correction_applied\": ocr_correction_applied\n","    }\n","\n","def process_test_dataset(test_data_dir, model, processor, label_info):\n","    \"\"\"테스트 데이터셋 전체 처리\"\"\"\n","    print(f\"\\n🔍 테스트 데이터셋 처리 시작: {test_data_dir}\")\n","    print(\"=\"*60)\n","    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n","\n","    total_processed = 0\n","    total_correct = 0\n","    class_results = defaultdict(lambda: {'correct': 0, 'total': 0, 'predictions': []})\n","\n","    # 각 클래스 폴더 처리\n","    for class_name in disposal_map.keys():\n","        class_dir = os.path.join(test_data_dir, class_name)\n","\n","        if not os.path.exists(class_dir):\n","            print(f\"⚠️  클래스 폴더가 없습니다: {class_name}\")\n","            continue\n","\n","        print(f\"\\n📂 처리 중: {class_name}\")\n","        image_files = []\n","        for ext in image_extensions:\n","            image_files.extend(glob.glob(os.path.join(class_dir, ext)))\n","\n","        if not image_files:\n","            print(f\"   ℹ️  이미지 파일이 없습니다.\")\n","            continue\n","\n","        print(f\"   📊 발견된 이미지: {len(image_files)}개\")\n","\n","        # 각 이미지 처리\n","        for i, image_path in enumerate(image_files, 1):\n","            try:\n","                result = classify_and_dispose(image_path, model, processor)\n","\n","                if result:\n","                    predicted_label = result['final_label']\n","                    confidence = result['final_confidence']\n","\n","                    # 결과 기록\n","                    class_results[class_name]['total'] += 1\n","                    class_results[class_name]['predictions'].append({\n","                        'file': os.path.basename(image_path),\n","                        'predicted': predicted_label,\n","                        'confidence': confidence,\n","                        'correct': predicted_label == class_name\n","                    })\n","\n","                    total_processed += 1\n","\n","                    if predicted_label == class_name:\n","                        class_results[class_name]['correct'] += 1\n","                        total_correct += 1\n","                        print(f\"      ✅ 정답: {predicted_label} (신뢰도: {confidence:.1%})\")\n","                    else:\n","                        print(f\"      ❌ 오답: {predicted_label} (신뢰도: {confidence:.1%}) - 정답: {class_name}\")\n","                else:\n","                    print(f\"      ⚠️  처리 실패\")\n","\n","            except Exception as e:\n","                print(f\"      ❌ 오류: {e}\")\n","                continue\n","\n","    return class_results, total_processed, total_correct\n","\n","def print_detailed_results(class_results, total_processed, total_correct):\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 평가 결과\")\n","    print(\"=\"*60)\n","\n","    overall_accuracy = (total_correct / total_processed * 100) if total_processed > 0 else 0\n","    print(f\"\\n🎯 전체 성능\")\n","    print(f\"   • 전체 정확도: {total_correct}/{total_processed} = {overall_accuracy:.2f}%\")\n","    print(f\"   • 처리된 총 이미지: {total_processed}개\")\n","\n","    print(f\"\\n📋 클래스별 상세 결과\")\n","    print(\"-\" * 60)\n","    print(f\"{'클래스명':<20} {'정확도':<15} {'정답/전체':<12} {'성능'}\")\n","    print(\"-\" * 60)\n","\n","    for class_name, results in class_results.items():\n","        if results['total'] > 0:\n","            accuracy = results['correct'] / results['total'] * 100\n","            ratio = f\"{results['correct']}/{results['total']}\"\n","\n","            if accuracy >= 90:\n","                performance = \"🟢 우수\"\n","            elif accuracy >= 70:\n","                performance = \"🟡 보통\"\n","            else:\n","                performance = \"🔴 개선필요\"\n","\n","            print(f\"{class_name:<20} {accuracy:<15.2f} {ratio:<12} {performance}\")\n","\n","    print(f\"\\n🔍 오분류 상세 분석\")\n","    print(\"-\" * 60)\n","\n","    for class_name, results in class_results.items():\n","        wrong_predictions = [p for p in results['predictions'] if not p['correct']]\n","\n","        if wrong_predictions:\n","            print(f\"\\n❌ {class_name} 오분류 케이스:\")\n","            for pred in wrong_predictions:\n","                print(f\"   • {pred['file']} → {pred['predicted']} (신뢰도: {pred['confidence']:.1%})\")\n","\n","    # 성능 개선 제안\n","    print(f\"\\n💡 성능 개선 제안\")\n","    print(\"-\" * 60)\n","\n","    low_performance_classes = []\n","    for class_name, results in class_results.items():\n","        if results['total'] > 0:\n","            accuracy = results['correct'] / results['total'] * 100\n","            if accuracy < 70:\n","                low_performance_classes.append((class_name, accuracy, results['total']))\n","\n","    if low_performance_classes:\n","        print(\"📉 성능이 낮은 클래스:\")\n","        for class_name, accuracy, total in low_performance_classes:\n","            print(f\"   • {class_name}: {accuracy:.1f}% (샘플 수: {total}개)\")\n","\n","    else:\n","        print(\"✅ 모든 클래스가 양호한 성능을 보입니다!\")\n","\n","def main():\n","    print(\"🏥 의약품 분류 및 분리배출 도우미 (콘솔 버전)\")\n","    print(\"=\"*60)\n","\n","    model, processor, label_info = load_model()\n","\n","    if model is None:\n","        print(\"❌ 모델 로드 실패. 프로그램을 종료합니다.\")\n","        return\n","\n","    test_data_dir = \"/content/drive/MyDrive/trash_ai/final_test\"\n","    class_results, total_processed, total_correct = process_test_dataset(\n","        test_data_dir, model, processor, label_info\n","    )\n","\n","    print_detailed_results(class_results, total_processed, total_correct)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6lWC852ArZw","executionInfo":{"status":"ok","timestamp":1748626640705,"user_tz":-540,"elapsed":89572,"user":{"displayName":"히힛","userId":"14574132926497786353"}},"outputId":"408bb3cb-f70b-420e-e5f7-c22e66c16896"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🏥 의약품 분류 및 분리배출 도우미 (콘솔 버전)\n","============================================================\n","🔄 모델 로딩 중...\n","✅ 모델 로딩 완료!\n","📋 로드된 클래스: ['알약_블리스터팩', '알약_블리스터팩_박스', '안약', '연고', '유리병']\n","\n","🔍 테스트 데이터셋 처리 시작: /content/drive/MyDrive/trash_ai/final_test\n","============================================================\n","\n","📂 처리 중: 알약_블리스터팩\n","   📊 발견된 이미지: 6개\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 91.8%)\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 53.7%)\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 98.2%)\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 81.5%)\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 95.5%)\n","      ✅ 정답: 알약_블리스터팩 (신뢰도: 94.8%)\n","\n","📂 처리 중: 알약_블리스터팩_박스\n","   📊 발견된 이미지: 7개\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 99.4%)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 97.8%)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 99.3%)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 84.1%)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 99.1%)\n","라벨 알약_블리스터팩 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 알약_블리스터팩_박스 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 유리병 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 99.5%)\n","라벨 알약_블리스터팩 점수 증가: +0.300 (키워드: pill, 개수: 2)\n","라벨 알약_블리스터팩_박스 점수 증가: +0.300 (키워드: pill, 개수: 2)\n","라벨 연고 점수 증가: +0.150 (키워드: ointment, 개수: 1)\n","라벨 유리병 점수 증가: +0.300 (키워드: pill, 개수: 2)\n","      ✅ 정답: 알약_블리스터팩_박스 (신뢰도: 99.4%)\n","\n","📂 처리 중: 안약\n","   📊 발견된 이미지: 8개\n","      ❌ 오답: 알약_블리스터팩_박스 (신뢰도: 83.0%) - 정답: 안약\n","      ✅ 정답: 안약 (신뢰도: 99.2%)\n","      ✅ 정답: 안약 (신뢰도: 98.0%)\n","      ✅ 정답: 안약 (신뢰도: 99.3%)\n","라벨 알약_블리스터팩 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 알약_블리스터팩_박스 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 유리병 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","      ✅ 정답: 안약 (신뢰도: 88.8%)\n","라벨 안약 점수 증가: +0.150 (키워드: eye_drop, 개수: 1)\n","      ✅ 정답: 안약 (신뢰도: 64.1%)\n","      ✅ 정답: 안약 (신뢰도: 73.0%)\n","      ✅ 정답: 안약 (신뢰도: 75.6%)\n","\n","📂 처리 중: 연고\n","   📊 발견된 이미지: 7개\n","라벨 연고 점수 증가: +0.150 (키워드: ointment, 개수: 1)\n","      ✅ 정답: 연고 (신뢰도: 99.4%)\n","      ✅ 정답: 연고 (신뢰도: 99.9%)\n","라벨 연고 점수 증가: +0.150 (키워드: ointment, 개수: 1)\n","      ✅ 정답: 연고 (신뢰도: 99.6%)\n","라벨 연고 점수 증가: +0.150 (키워드: ointment, 개수: 1)\n","      ✅ 정답: 연고 (신뢰도: 97.1%)\n","      ✅ 정답: 연고 (신뢰도: 97.7%)\n","라벨 연고 점수 증가: +0.150 (키워드: ointment, 개수: 1)\n","      ❌ 오답: 알약_블리스터팩_박스 (신뢰도: 87.5%) - 정답: 연고\n","라벨 알약_블리스터팩 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 알약_블리스터팩_박스 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","라벨 유리병 점수 증가: +0.150 (키워드: pill, 개수: 1)\n","      ✅ 정답: 연고 (신뢰도: 99.7%)\n","\n","📂 처리 중: 유리병\n","   📊 발견된 이미지: 5개\n","      ✅ 정답: 유리병 (신뢰도: 77.5%)\n","      ❌ 오답: 안약 (신뢰도: 74.8%) - 정답: 유리병\n","      ❌ 오답: 안약 (신뢰도: 77.9%) - 정답: 유리병\n","      ❌ 오답: 알약_블리스터팩_박스 (신뢰도: 91.9%) - 정답: 유리병\n","      ✅ 정답: 유리병 (신뢰도: 54.0%)\n","\n","============================================================\n","📊 최종 평가 결과\n","============================================================\n","\n","🎯 전체 성능\n","   • 전체 정확도: 28/33 = 84.85%\n","   • 처리된 총 이미지: 33개\n","\n","📋 클래스별 상세 결과\n","------------------------------------------------------------\n","클래스명                 정확도             정답/전체        성능\n","------------------------------------------------------------\n","알약_블리스터팩             100.00          6/6          🟢 우수\n","알약_블리스터팩_박스          100.00          7/7          🟢 우수\n","안약                   87.50           7/8          🟡 보통\n","연고                   85.71           6/7          🟡 보통\n","유리병                  40.00           2/5          🔴 개선필요\n","\n","🔍 오분류 상세 분석\n","------------------------------------------------------------\n","\n","❌ 안약 오분류 케이스:\n","   • 2.jpg → 알약_블리스터팩_박스 (신뢰도: 83.0%)\n","\n","❌ 연고 오분류 케이스:\n","   • image.png → 알약_블리스터팩_박스 (신뢰도: 87.5%)\n","\n","❌ 유리병 오분류 케이스:\n","   • 20230922115540_80A32.jpg → 안약 (신뢰도: 74.8%)\n","   • output_1261293561.jpg → 안약 (신뢰도: 77.9%)\n","   • 72432_60742_3559.jpg → 알약_블리스터팩_박스 (신뢰도: 91.9%)\n","\n","💡 성능 개선 제안\n","------------------------------------------------------------\n","📉 성능이 낮은 클래스:\n","   • 유리병: 40.0% (샘플 수: 5개)\n"]}]},{"cell_type":"markdown","source":["### streamlit_code"],"metadata":{"id":"Z2Dcr0LADOOF"}},{"cell_type":"code","source":["streamlit_code = '''\n","import json\n","import streamlit as st\n","import torch\n","from PIL import Image\n","from transformers import CLIPProcessor, CLIPModel\n","import os\n","from google.colab import userdata\n","import cv2\n","import numpy as np\n","import requests\n","import base64\n","import uuid\n","import time\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","st.set_page_config(\n","    page_title=\"의약품 분리배출 AI\",\n","    page_icon=\"🏥\",\n","    layout=\"wide\"\n",")\n","\n","disposal_map = {\n","    \"알약_블리스터팩\": \"겉 포장지(종이 또는 플라스틱 필름)를 제거하고, 플라스틱 블리스터팩은 그대로 의약품 수거함에 버리세요.\",\n","    \"알약_블리스터팩_박스\": \"종이 박스는 분리하여 종이 재활용함에 버리고, 겉 포장지(종이 또는 플라스틱 필름)를 제거한 후 플라스틱 블리스터팩은 의약품 수거함에 버리세요.\",\n","    \"유리병\": \"약은 폐의약품 수거함에 버리고, 유리병은 내용물을 완전히 비운 후 깨끗이 헹궈 병류로 분리배출하세요.\",\n","    \"안약\": \"용기 그대로 의약품 수거함에 버리세요. 남은 약액은 그대로 두셔도 됩니다.\",\n","    \"연고\": \"튜브를 완전히 비우고 의약품 수거함에 버리세요.\"\n","}\n","\n","text_descriptions = [\n","    \"pill blister pack with plastic packaging\",\n","    \"pill blister pack in cardboard box\",\n","    \"glass bottle for medicine\",\n","    \"small eye drop bottle\",\n","    \"ointment tube for skin\"\n","]\n","\n","labels = [\"알약_블리스터팩\", \"알약_블리스터팩_박스\", \"유리병\", \"안약\", \"연고\"]\n","\n","folder_to_label = {\n","    \"알약_블리스터팩\": 0,\n","    \"알약_블리스터팩_박스\": 1,\n","    \"유리병\": 2,\n","    \"안약\": 3,\n","    \"연고\": 4\n","}\n","\n","medication_keywords = {\n","    \"pill_related\": [\n","        \"캡슐\", \"mg\", \"정\", \"캡\", \"알약\", \"환\", \"tablet\", \"capsule\", \"cap\", \"pill\",\n","        \"Tablet\", \"Capsule\", \"Cap\", \"Pill\", \"TABLET\", \"CAPSULE\", \"CAP\", \"PILL\",\n","        \"MG\", \"mg\", \"Mg\", \"mcg\", \"µg\", \"IU\", \"unit\", \"Units\", \"UNITS\"\n","    ],\n","    \"ointment_related\": [\n","        \"연고\", \"크림\", \"젤\", \"로션\", \"밤\", \"연고제\", \"%\",\n","        \"ointment\", \"cream\", \"gel\", \"lotion\", \"balm\",\n","        \"Ointment\", \"Cream\", \"Gel\", \"Lotion\", \"Balm\",\n","        \"OINTMENT\", \"CREAM\", \"GEL\", \"LOTION\", \"BALM\"\n","    ],\n","    \"eye_drop_related\": [\n","        \"안약\", \"점안액\", \"점안제\", \"eye\", \"drop\", \"drops\",\n","        \"Eye\", \"Drop\", \"Drops\", \"EYE\", \"DROP\", \"DROPS\",\n","        \"ophthalmic\", \"Ophthalmic\", \"OPHTHALMIC\"\n","    ]\n","}\n","\n","def analyze_medication_keywords(ocr_text):\n","    if not ocr_text:\n","        return {\"pill\": 0, \"ointment\": 0, \"eye_drop\": 0}, {}\n","\n","    scores = {\n","        \"pill\": 0,\n","        \"ointment\": 0,\n","        \"eye_drop\": 0\n","    }\n","\n","    found_keywords = {\n","        \"pill\": [],\n","        \"ointment\": [],\n","        \"eye_drop\": []\n","    }\n","\n","    for keyword in medication_keywords[\"pill_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"pill\"] += 1\n","            found_keywords[\"pill\"].append(keyword)\n","\n","    for keyword in medication_keywords[\"ointment_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"ointment\"] += 1\n","            found_keywords[\"ointment\"].append(keyword)\n","\n","    for keyword in medication_keywords[\"eye_drop_related\"]:\n","        if keyword in ocr_text:\n","            scores[\"eye_drop\"] += 1\n","            found_keywords[\"eye_drop\"].append(keyword)\n","    return scores, found_keywords\n","\n","def adjust_clip_predictions(logits, keyword_scores, boost_factor=0.15):\n","\n","    adjusted_logits = logits.clone()\n","\n","    label_keyword_mapping = {\n","        0: \"pill\",      # 알약_블리스터팩\n","        1: \"pill\",      # 알약_블리스터팩_박스\n","        2: \"pill\",      # 유리병\n","        3: \"eye_drop\",  # 안약\n","        4: \"ointment\"   # 연고\n","    }\n","\n","    adjustments = {}\n","    for label_idx, keyword_type in label_keyword_mapping.items():\n","        if keyword_scores[keyword_type] > 0:\n","            boost = boost_factor * keyword_scores[keyword_type]\n","            adjusted_logits[0][label_idx] += boost\n","            adjustments[labels[label_idx]] = boost\n","            print(f\"라벨 {labels[label_idx]} 점수 증가: +{boost:.3f} (키워드: {keyword_type}, 개수: {keyword_scores[keyword_type]})\")\n","\n","    return adjusted_logits, adjustments\n","\n","def preprocess_image_for_ocr(image):\n","    try:\n","        img_array = np.array(image)\n","\n","        if len(img_array.shape) == 3:\n","            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n","        else:\n","            img_bgr = img_array\n","\n","        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","        denoised = cv2.medianBlur(gray, 3)\n","        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","        enhanced = clahe.apply(denoised)\n","        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)\n","        binary_inv = cv2.adaptiveThreshold(\n","            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n","        )\n","        kernel = np.ones((1, 1), np.uint8)\n","        processed = cv2.morphologyEx(binary_inv, cv2.MORPH_CLOSE, kernel)\n","\n","        result_image = Image.fromarray(processed)\n","\n","        return result_image\n","\n","    except Exception as e:\n","        print(f\"이미지 전처리 오류: {e}\")\n","        return image\n","\n","def extract_text_from_image_with_clova(image_path: str):\n","    secret_key = userdata.get(\"OCR_CLOVA\")\n","    api_url = \"https://s79a9gvq9a.apigw.ntruss.com/custom/v1/42492/9274a7c96357207aa7e436c070ceba3fecf0b7f91679a2a8f72283f165493853/general\"\n","\n","    file_size = os.path.getsize(image_path)\n","    if file_size > 5 * 1024 * 1024:  # 5MB\n","        print(\"⚠️ 파일 크기가 5MB를 초과합니다.\")\n","\n","    with open(image_path, \"rb\") as f:\n","        image_data = base64.b64encode(f.read()).decode()\n","\n","    headers = {\n","        \"X-OCR-SECRET\": secret_key,\n","        \"Content-Type\": \"application/json\"\n","    }\n","\n","    payload = {\n","        \"version\": \"V2\",\n","        \"requestId\": str(uuid.uuid4()),\n","        \"timestamp\": int(time.time() * 1000),\n","        \"images\": [{\n","            \"name\": \"temp\",\n","            \"format\": \"jpg\",\n","            \"data\": image_data\n","        }]\n","    }\n","\n","    try:\n","        response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=30)\n","        result = response.json()\n","\n","        first_image = result[\"images\"][0]\n","        fields = first_image[\"fields\"]\n","        texts = []\n","\n","        for i, field in enumerate(fields):\n","            if \"inferText\" in field and field[\"inferText\"]:\n","                text = field[\"inferText\"]\n","                texts.append(text)\n","                confidence = field.get(\"inferConfidence\", \"N/A\")\n","                print(f\"텍스트 {i+1}: '{text}' (신뢰도: {confidence})\")\n","\n","        if not texts:\n","            return \"\", 0.0\n","\n","        extracted_text = \" \".join(texts)\n","        return extracted_text, confidence\n","\n","    except Exception as e:\n","        print(f\"❌ OCR API 호출 오류: {e}\")\n","        return \"\", 0.0\n","\n","def classify_and_dispose(image_path: str, model_clip, processor_clip):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    image = Image.open(image_path).convert(\"RGB\")\n","\n","    processed_image = preprocess_image_for_ocr(image)\n","    temp_path = \"temp_processed.png\"\n","    processed_image.save(temp_path)\n","\n","    ocr_text, ocr_confidence = extract_text_from_image_with_clova(temp_path)\n","    if ocr_text is None:\n","        ocr_text = \"\"\n","\n","    keyword_scores, found_keywords = analyze_medication_keywords(ocr_text)\n","\n","    inputs = processor_clip(text=text_descriptions, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model_clip(**inputs)\n","\n","    original_logits = outputs.logits_per_image\n","    adjusted_logits, logit_adjustments = adjust_clip_predictions(original_logits, keyword_scores)\n","\n","    original_probs = original_logits.softmax(dim=1)\n","    adjusted_probs = adjusted_logits.softmax(dim=1)\n","\n","    original_predicted_idx = torch.argmax(original_probs, dim=1).item()\n","    original_predicted_label = labels[original_predicted_idx]\n","    original_confidence = torch.max(original_probs).item()\n","\n","    predicted_idx = torch.argmax(adjusted_probs, dim=1).item()\n","    predicted_label = labels[predicted_idx]\n","    confidence = torch.max(adjusted_probs).item()\n","\n","    final_label = predicted_label\n","    ocr_correction_applied = False\n","\n","    if keyword_scores[\"ointment\"] >= 1 and predicted_label != \"연고\":\n","        if confidence < 0.7:\n","            final_label = \"연고\"\n","            confidence = min(confidence + 0.15, 0.95)\n","            ocr_correction_applied = True\n","\n","    if keyword_scores[\"eye_drop\"] >= 1 and predicted_label != \"안약\":\n","        if confidence < 0.7:\n","            final_label = \"안약\"\n","            confidence = min(confidence + 0.15, 0.95)\n","            ocr_correction_applied = True\n","\n","    context = disposal_map.get(final_label, \"종류에 따라 적절한 방법으로 의약품 수거함에 버리세요.\")\n","\n","    return {\n","        \"final_label\": final_label,\n","        \"disposal_context\": context,\n","        \"final_confidence\": confidence,\n","        \"ocr_text\": ocr_text,\n","        \"ocr_confidence\" : ocr_confidence,\n","        \"original_clip_label\": original_predicted_label,\n","        \"original_clip_confidence\": original_confidence,\n","        \"adjusted_clip_label\": predicted_label,\n","        \"adjusted_clip_confidence\": torch.max(adjusted_probs).item(),\n","        \"keyword_scores\": keyword_scores,\n","        \"found_keywords\": found_keywords,\n","        \"logit_adjustments\": logit_adjustments,\n","        \"ocr_correction_applied\": ocr_correction_applied\n","    }\n","\n","@st.cache_resource\n","def load_model():\n","    try:\n","        model_path = \"/content/drive/MyDrive/trash_ai/clip_medication_test/best\"\n","        if os.path.exists(model_path):\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            model = CLIPModel.from_pretrained(model_path).to(device)\n","            processor = CLIPProcessor.from_pretrained(model_path)\n","            return model, processor\n","        else:\n","            st.error(f\"❌ 모델 경로를 찾을 수 없습니다: {model_path}\")\n","            return None, None\n","    except Exception as e:\n","        st.error(f\"❌ 모델 로딩 오류: {str(e)}\")\n","        return None, None\n","\n","def main():\n","    st.title(\"🏥 의약품 분리배출 AI\")\n","    st.markdown(\"---\")\n","    st.write(\"의약품 이미지를 업로드하면 종류를 분류하고 올바른 분리배출 방법을 알려드립니다.\")\n","\n","    with st.sidebar:\n","        st.header(\"📋 분류 가능한 의약품\")\n","        st.write(\"• 💊 알약 블리스터팩\")\n","        st.write(\"• 📦 알약 블리스터팩 (박스 포함)\")\n","        st.write(\"• 🍼 유리병\")\n","        st.write(\"• 👁️ 안약\")\n","        st.write(\"• 🧴 연고\")\n","\n","        st.header(\"📖 사용 방법\")\n","        st.write(\"1. 의약품 사진 업로드\")\n","        st.write(\"2. AI 자동 분석 대기\")\n","        st.write(\"3. 분리배출 방법 확인\")\n","        st.warning(\"⚠️ 텍스트가 선명하게 보이도록 촬영하면 더 정확한 분류가 가능합니다.\")\n","\n","        st.header(\"🔧 시스템 정보\")\n","        device = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n","        st.write(f\"디바이스: {device}\")\n","\n","    with st.spinner(\"모델 로딩 중... 잠시만 기다려주세요.\"):\n","        model_clip, processor_clip = load_model()\n","\n","    if model_clip is None or processor_clip is None:\n","        st.error(\"🚫 모델을 로드할 수 없습니다. 모델 경로와 파일을 확인해주세요.\")\n","        st.info(\"💡 모델 학습이 완료되었는지 확인하세요.\")\n","        return\n","\n","    st.success(\"✅ 모델 로딩 완료!\")\n","\n","    uploaded_file = st.file_uploader(\n","        \"📸 의약품 이미지를 업로드하세요\",\n","        type=[\"jpg\", \"jpeg\", \"png\"],\n","        help=\"JPG, JPEG, PNG 형식의 이미지를 업로드할 수 있습니다. 텍스트가 선명하게 보이는 이미지일수록 정확도가 높아집니다.\"\n","    )\n","\n","    if uploaded_file is not None:\n","        try:\n","            col1, col2 = st.columns([1, 1])\n","\n","            with col1:\n","                st.subheader(\"📷 업로드된 이미지\")\n","                st.image(uploaded_file, caption=\"분석할 이미지\", use_container_width=True)\n","\n","            temp_path = f\"temp_{uploaded_file.name}\"\n","            with open(temp_path, \"wb\") as f:\n","                f.write(uploaded_file.getbuffer())\n","\n","            if st.button(\"🔍 분석 시작\", type=\"primary\"):\n","                with col2:\n","                    st.subheader(\"📊 분석 결과\")\n","\n","                    # 프로그레스 바\n","                    progress_bar = st.progress(0)\n","                    status_text = st.empty()\n","\n","                    status_text.text(\"이미지 전처리 중...\")\n","                    progress_bar.progress(20)\n","\n","                    status_text.text(\"OCR 텍스트 추출 중...\")\n","                    progress_bar.progress(40)\n","\n","                    status_text.text(\"키워드 분석 중...\")\n","                    progress_bar.progress(50)\n","\n","                    status_text.text(\"AI 모델 실행 중...\")\n","                    progress_bar.progress(70)\n","\n","                    result = classify_and_dispose(temp_path, model_clip, processor_clip)\n","\n","                    progress_bar.progress(90)\n","                    status_text.text(\"결과 생성 중...\")\n","\n","                    progress_bar.progress(100)\n","                    status_text.text(\"분석 완료!\")\n","\n","                    st.success(\"✅ 분석 완료!\")\n","\n","                    st.markdown(f\"\"\"\n","                    <div style=\"padding: 1rem; border-radius: 0.5rem; background-color: #e8f4fd; margin: 1rem 0; border-left: 4px solid #1f77b4;\">\n","                        <h3>🔍 최종 분류 결과: {result['final_label']}</h3>\n","                    </div>\n","                    \"\"\", unsafe_allow_html=True)\n","\n","                    if result['final_confidence'] > 0.8:\n","                        st.success(f\"📊 신뢰도: {result['final_confidence']:.1%} (높음)\")\n","                    elif result['final_confidence'] > 0.6:\n","                        st.warning(f\"📊 신뢰도: {result['final_confidence']:.1%} (보통)\")\n","                    else:\n","                        st.error(f\"📊 신뢰도: {result['final_confidence']:.1%} (낮음)\")\n","                        st.warning(\"신뢰도가 낮습니다. 더 선명한 이미지를 사용해보세요.\")\n","\n","                    st.info(f\"\"\"♻️ **분리배출 방법**: {result['disposal_context']}\"\"\")\n","\n","                    with st.expander(\"🔍 분석 과정 상세 정보\", expanded=True):\n","                        st.markdown(\"### 1️⃣ CLIP 모델 원본 예측\")\n","                        st.write(f\"- 예측: **{result['original_clip_label']}**\")\n","                        st.write(f\"- 신뢰도: {result['original_clip_confidence']:.1%}\")\n","\n","                        st.markdown(\"### 2️⃣ OCR 키워드 분석\")\n","                        if result['ocr_text'] and result['ocr_confidence']:\n","                            st.write(\"**추출된 텍스트:**\")\n","                            st.code(result['ocr_text'])\n","                            st.write(\"**OCR 결과 신뢰도:**\")\n","                            st.code(result['ocr_confidence'])\n","\n","                            col_k1, col_k2 = st.columns(2)\n","                            with col_k1:\n","                                st.write(\"**키워드 점수:**\")\n","                                for category, score in result['keyword_scores'].items():\n","                                    emoji = {\"pill\": \"💊\", \"liquid\": \"🧴\", \"ointment\": \"🧴\", \"eye_drop\": \"👁️\"}\n","                                    st.write(f\"{emoji.get(category, '•')} {category}: {score}개\")\n","\n","                            with col_k2:\n","                                st.write(\"**발견된 키워드:**\")\n","                                for category, keywords in result['found_keywords'].items():\n","                                    if keywords:\n","                                        st.write(f\"**{category}:** {', '.join(keywords)}\")\n","                        else:\n","                            st.warning(\"OCR로 텍스트를 추출하지 못했습니다.\")\n","\n","                        st.markdown(\"### 3️⃣ 키워드 기반 점수 조정\")\n","                        if result['logit_adjustments']:\n","                            st.write(\"**점수 조정 내역:**\")\n","                            for label, boost in result['logit_adjustments'].items():\n","                                st.write(f\"- {label}: +{boost:.3f}\")\n","                            st.write(f\"- 조정 후 예측: **{result['adjusted_clip_label']}**\")\n","                            st.write(f\"- 조정 후 신뢰도: {result['adjusted_clip_confidence']:.1%}\")\n","                        else:\n","                            st.write(\"키워드 기반 점수 조정이 적용되지 않았습니다.\")\n","\n","                        st.markdown(\"### 4️⃣ OCR 기반 최종 보정\")\n","                        if result['ocr_correction_applied']:\n","                            st.success(f\"✅ OCR 키워드 기반으로 '{result['final_label']}'로 최종 보정되었습니다.\")\n","                        else:\n","                            st.info(\"OCR 기반 추가 보정이 적용되지 않았습니다.\")\n","\n","                        st.markdown(\"### 📋 변경 사항 요약\")\n","                        changes = []\n","                        if result['original_clip_label'] != result['adjusted_clip_label']:\n","                            changes.append(f\"CLIP 키워드 조정: {result['original_clip_label']} → {result['adjusted_clip_label']}\")\n","                        if result['ocr_correction_applied']:\n","                            changes.append(f\"OCR 기반 보정: {result['adjusted_clip_label']} → {result['final_label']}\")\n","\n","                        if changes:\n","                            for change in changes:\n","                                st.write(f\"• {change}\")\n","                        else:\n","                            st.write(\"• 원본 CLIP 예측이 그대로 유지되었습니다.\")\n","\n","            if os.path.exists(temp_path):\n","                os.remove(temp_path)\n","\n","        except Exception as e:\n","            st.error(f\"❌ 분석 중 오류가 발생했습니다: {str(e)}\")\n","            st.write(\"오류 상세 정보:\")\n","            st.code(str(e))\n","\n","    st.markdown(\"---\")\n","    st.markdown(\n","        \"<div style='text-align: center; color: #666;'>\"\n","        \"<p>🌱 환경을 생각하는 AI 기반 의약품 분리배출 도우미 (키워드 분석 시각화 버전)</p>\"\n","        \"</div>\",\n","        unsafe_allow_html=True\n","    )\n","\n","if __name__ == \"__main__\":\n","    main()\n","'''\n","\n","with open(\"/content/drive/MyDrive/trash_ai/medicine_app.py\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(streamlit_code)"],"metadata":{"id":"etovEbT3tOGq","executionInfo":{"status":"ok","timestamp":1750607980262,"user_tz":-540,"elapsed":1332,"user":{"displayName":"김세희","userId":"10121931475775017609"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import threading\n","import subprocess\n","import time\n","from google.colab import output\n","\n","def start_streamlit():\n","    subprocess.run([\n","        \"streamlit\", \"run\", \"/content/drive/MyDrive/trash_ai/medicine_app.py\",\n","        \"--server.port\", \"8502\",\n","        \"--server.address\", \"0.0.0.0\",\n","        \"--server.headless\", \"true\",\n","        \"--server.fileWatcherType\", \"none\",\n","        \"--server.enableXsrfProtection\", \"false\",\n","        \"--browser.gatherUsageStats\", \"false\",\n","        \"--server.enableWebsocketCompression\", \"false\",\n","        \"--server.enableCORS\", \"false\"\n","    ])\n","\n","thread = threading.Thread(target=start_streamlit)\n","thread.daemon = True\n","thread.start()\n","\n","print(\"⏳ 의약품 분리배출 AI 시작 중...\")\n","print(\"브라우저에서 아래 URL로 접속하세요:\")\n","\n","# Colab의 권장 방법 사용 - iframe\n","try:\n","    output.serve_kernel_port_as_iframe(8502, height=800)\n","except:\n","    print(\"http://localhost:8502\")\n","    print(\"또는 포트 포워딩 URL을 사용하세요.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":857},"id":"oqFf64X60bjp","outputId":"4f344593-64b2-4a41-dc4a-0de4ebe8cf4d","executionInfo":{"status":"ok","timestamp":1750604967013,"user_tz":-540,"elapsed":13,"user":{"displayName":"김세희","userId":"10121931475775017609"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["⏳ 의약품 분리배출 AI 시작 중...\n","브라우저에서 아래 URL로 접속하세요:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","    if (!google.colab.kernel.accessAllowed && !cache) {\n","      return;\n","    }\n","    element.appendChild(document.createTextNode(''));\n","    const url = await google.colab.kernel.proxyPort(port, {cache});\n","    const iframe = document.createElement('iframe');\n","    iframe.src = new URL(path, url).toString();\n","    iframe.height = height;\n","    iframe.width = width;\n","    iframe.style.border = 0;\n","    iframe.allow = [\n","        'accelerometer',\n","        'autoplay',\n","        'camera',\n","        'clipboard-read',\n","        'clipboard-write',\n","        'gyroscope',\n","        'magnetometer',\n","        'microphone',\n","        'serial',\n","        'usb',\n","        'xr-spatial-tracking',\n","    ].join('; ');\n","    element.appendChild(iframe);\n","  })(8502, \"/\", \"100%\", 800, false, window.element)"]},"metadata":{}}]},{"cell_type":"code","source":["def kill_existing_streamlit():\n","    try:\n","        result = subprocess.run(['pgrep', '-f', 'streamlit'], capture_output=True, text=True)\n","        if result.stdout:\n","            pids = result.stdout.strip().split('\\n')\n","            for pid in pids:\n","                if pid:\n","                    try:\n","                        os.kill(int(pid), signal.SIGTERM)\n","                        print(f\"종료된 PID: {pid}\")\n","                    except:\n","                        pass\n","        subprocess.run(['fuser', '-k', '8501/tcp'], capture_output=True)\n","        print(\"기존 프로세스 정리 완료\")\n","    except Exception as e:\n","        print(f\"프로세스 정리 중 오류: {e}\")\n","\n","kill_existing_streamlit()"],"metadata":{"id":"Dj3nONdn1GdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750604869381,"user_tz":-540,"elapsed":37,"user":{"displayName":"김세희","userId":"10121931475775017609"}},"outputId":"798de5b6-1601-42e6-b08a-477de7115fa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["기존 프로세스 정리 완료\n"]}]}]}