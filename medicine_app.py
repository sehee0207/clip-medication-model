
import json
import streamlit as st
import torch
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import os
from google.colab import userdata
import cv2
import numpy as np
import requests
import base64
import uuid
import time
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch.optim as optim
import torch.nn.functional as F

st.set_page_config(
    page_title="ì˜ì•½í’ˆ ë¶„ë¦¬ë°°ì¶œ AI",
    page_icon="ğŸ¥",
    layout="wide"
)

disposal_map = {
    "ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©": "ê²‰ í¬ì¥ì§€(ì¢…ì´ ë˜ëŠ” í”Œë¼ìŠ¤í‹± í•„ë¦„)ë¥¼ ì œê±°í•˜ê³ , í”Œë¼ìŠ¤í‹± ë¸”ë¦¬ìŠ¤í„°íŒ©ì€ ê·¸ëŒ€ë¡œ ì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ì„¸ìš”.",
    "ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©_ë°•ìŠ¤": "ì¢…ì´ ë°•ìŠ¤ëŠ” ë¶„ë¦¬í•˜ì—¬ ì¢…ì´ ì¬í™œìš©í•¨ì— ë²„ë¦¬ê³ , ê²‰ í¬ì¥ì§€(ì¢…ì´ ë˜ëŠ” í”Œë¼ìŠ¤í‹± í•„ë¦„)ë¥¼ ì œê±°í•œ í›„ í”Œë¼ìŠ¤í‹± ë¸”ë¦¬ìŠ¤í„°íŒ©ì€ ì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ì„¸ìš”.",
    "ìœ ë¦¬ë³‘": "ì•½ì€ íì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ê³ , ìœ ë¦¬ë³‘ì€ ë‚´ìš©ë¬¼ì„ ì™„ì „íˆ ë¹„ìš´ í›„ ê¹¨ë—ì´ í—¹ê¶ˆ ë³‘ë¥˜ë¡œ ë¶„ë¦¬ë°°ì¶œí•˜ì„¸ìš”.",
    "ì•ˆì•½": "ìš©ê¸° ê·¸ëŒ€ë¡œ ì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ì„¸ìš”. ë‚¨ì€ ì•½ì•¡ì€ ê·¸ëŒ€ë¡œ ë‘ì…”ë„ ë©ë‹ˆë‹¤.",
    "ì—°ê³ ": "íŠœë¸Œë¥¼ ì™„ì „íˆ ë¹„ìš°ê³  ì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ì„¸ìš”."
}

text_descriptions = [
    "pill blister pack with plastic packaging",
    "pill blister pack in cardboard box",
    "glass bottle for medicine",
    "small eye drop bottle",
    "ointment tube for skin"
]

labels = ["ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©", "ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©_ë°•ìŠ¤", "ìœ ë¦¬ë³‘", "ì•ˆì•½", "ì—°ê³ "]

folder_to_label = {
    "ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©": 0,
    "ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©_ë°•ìŠ¤": 1,
    "ìœ ë¦¬ë³‘": 2,
    "ì•ˆì•½": 3,
    "ì—°ê³ ": 4
}

medication_keywords = {
    "pill_related": [
        "ìº¡ìŠ", "mg", "ì •", "ìº¡", "ì•Œì•½", "í™˜", "tablet", "capsule", "cap", "pill",
        "Tablet", "Capsule", "Cap", "Pill", "TABLET", "CAPSULE", "CAP", "PILL",
        "MG", "mg", "Mg", "mcg", "Âµg", "IU", "unit", "Units", "UNITS"
    ],
    "ointment_related": [
        "ì—°ê³ ", "í¬ë¦¼", "ì ¤", "ë¡œì…˜", "ë°¤", "ì—°ê³ ì œ", "%",
        "ointment", "cream", "gel", "lotion", "balm",
        "Ointment", "Cream", "Gel", "Lotion", "Balm",
        "OINTMENT", "CREAM", "GEL", "LOTION", "BALM"
    ],
    "eye_drop_related": [
        "ì•ˆì•½", "ì ì•ˆì•¡", "ì ì•ˆì œ", "eye", "drop", "drops",
        "Eye", "Drop", "Drops", "EYE", "DROP", "DROPS",
        "ophthalmic", "Ophthalmic", "OPHTHALMIC"
    ]
}

def analyze_medication_keywords(ocr_text):
    if not ocr_text:
        return {"pill": 0, "ointment": 0, "eye_drop": 0}, {}

    scores = {
        "pill": 0,
        "ointment": 0,
        "eye_drop": 0
    }

    found_keywords = {
        "pill": [],
        "ointment": [],
        "eye_drop": []
    }

    for keyword in medication_keywords["pill_related"]:
        if keyword in ocr_text:
            scores["pill"] += 1
            found_keywords["pill"].append(keyword)

    for keyword in medication_keywords["ointment_related"]:
        if keyword in ocr_text:
            scores["ointment"] += 1
            found_keywords["ointment"].append(keyword)

    for keyword in medication_keywords["eye_drop_related"]:
        if keyword in ocr_text:
            scores["eye_drop"] += 1
            found_keywords["eye_drop"].append(keyword)
    return scores, found_keywords

def adjust_clip_predictions(logits, keyword_scores, boost_factor=0.15):

    adjusted_logits = logits.clone()

    label_keyword_mapping = {
        0: "pill",      # ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©
        1: "pill",      # ì•Œì•½_ë¸”ë¦¬ìŠ¤í„°íŒ©_ë°•ìŠ¤
        2: "pill",      # ìœ ë¦¬ë³‘
        3: "eye_drop",  # ì•ˆì•½
        4: "ointment"   # ì—°ê³ 
    }

    adjustments = {}
    for label_idx, keyword_type in label_keyword_mapping.items():
        if keyword_scores[keyword_type] > 0:
            boost = boost_factor * keyword_scores[keyword_type]
            adjusted_logits[0][label_idx] += boost
            adjustments[labels[label_idx]] = boost
            print(f"ë¼ë²¨ {labels[label_idx]} ì ìˆ˜ ì¦ê°€: +{boost:.3f} (í‚¤ì›Œë“œ: {keyword_type}, ê°œìˆ˜: {keyword_scores[keyword_type]})")

    return adjusted_logits, adjustments

def preprocess_image_for_ocr(image):
    try:
        img_array = np.array(image)

        if len(img_array.shape) == 3:
            img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = img_array

        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        denoised = cv2.medianBlur(gray, 3)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)
        binary_inv = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2
        )
        kernel = np.ones((1, 1), np.uint8)
        processed = cv2.morphologyEx(binary_inv, cv2.MORPH_CLOSE, kernel)

        result_image = Image.fromarray(processed)

        return result_image

    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return image

def extract_text_from_image_with_clova(image_path: str):
    secret_key = userdata.get("OCR_CLOVA")
    api_url = "https://s79a9gvq9a.apigw.ntruss.com/custom/v1/42492/9274a7c96357207aa7e436c070ceba3fecf0b7f91679a2a8f72283f165493853/general"

    file_size = os.path.getsize(image_path)
    if file_size > 5 * 1024 * 1024:  # 5MB
        print("âš ï¸ íŒŒì¼ í¬ê¸°ê°€ 5MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode()

    headers = {
        "X-OCR-SECRET": secret_key,
        "Content-Type": "application/json"
    }

    payload = {
        "version": "V2",
        "requestId": str(uuid.uuid4()),
        "timestamp": int(time.time() * 1000),
        "images": [{
            "name": "temp",
            "format": "jpg",
            "data": image_data
        }]
    }

    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=30)
        result = response.json()

        first_image = result["images"][0]
        fields = first_image["fields"]
        texts = []

        for i, field in enumerate(fields):
            if "inferText" in field and field["inferText"]:
                text = field["inferText"]
                texts.append(text)
                confidence = field.get("inferConfidence", "N/A")
                print(f"í…ìŠ¤íŠ¸ {i+1}: '{text}' (ì‹ ë¢°ë„: {confidence})")

        if not texts:
            return "", 0.0

        extracted_text = " ".join(texts)
        return extracted_text, confidence

    except Exception as e:
        print(f"âŒ OCR API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return "", 0.0

def classify_and_dispose(image_path: str, model_clip, processor_clip):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    image = Image.open(image_path).convert("RGB")

    processed_image = preprocess_image_for_ocr(image)
    temp_path = "temp_processed.png"
    processed_image.save(temp_path)

    ocr_text, ocr_confidence = extract_text_from_image_with_clova(temp_path)
    if ocr_text is None:
        ocr_text = ""

    keyword_scores, found_keywords = analyze_medication_keywords(ocr_text)

    inputs = processor_clip(text=text_descriptions, images=image, return_tensors="pt", padding=True, truncation=True)
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model_clip(**inputs)

    original_logits = outputs.logits_per_image
    adjusted_logits, logit_adjustments = adjust_clip_predictions(original_logits, keyword_scores)

    original_probs = original_logits.softmax(dim=1)
    adjusted_probs = adjusted_logits.softmax(dim=1)

    original_predicted_idx = torch.argmax(original_probs, dim=1).item()
    original_predicted_label = labels[original_predicted_idx]
    original_confidence = torch.max(original_probs).item()

    predicted_idx = torch.argmax(adjusted_probs, dim=1).item()
    predicted_label = labels[predicted_idx]
    confidence = torch.max(adjusted_probs).item()

    final_label = predicted_label
    ocr_correction_applied = False

    if keyword_scores["ointment"] >= 1 and predicted_label != "ì—°ê³ ":
        if confidence < 0.7:
            final_label = "ì—°ê³ "
            confidence = min(confidence + 0.15, 0.95)
            ocr_correction_applied = True

    if keyword_scores["eye_drop"] >= 1 and predicted_label != "ì•ˆì•½":
        if confidence < 0.7:
            final_label = "ì•ˆì•½"
            confidence = min(confidence + 0.15, 0.95)
            ocr_correction_applied = True

    context = disposal_map.get(final_label, "ì¢…ë¥˜ì— ë”°ë¼ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ì˜ì•½í’ˆ ìˆ˜ê±°í•¨ì— ë²„ë¦¬ì„¸ìš”.")

    return {
        "final_label": final_label,
        "disposal_context": context,
        "final_confidence": confidence,
        "ocr_text": ocr_text,
        "ocr_confidence" : ocr_confidence,
        "original_clip_label": original_predicted_label,
        "original_clip_confidence": original_confidence,
        "adjusted_clip_label": predicted_label,
        "adjusted_clip_confidence": torch.max(adjusted_probs).item(),
        "keyword_scores": keyword_scores,
        "found_keywords": found_keywords,
        "logit_adjustments": logit_adjustments,
        "ocr_correction_applied": ocr_correction_applied
    }

@st.cache_resource
def load_model():
    try:
        model_path = "/content/drive/MyDrive/trash_ai/clip_medication_test/best"
        if os.path.exists(model_path):
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            model = CLIPModel.from_pretrained(model_path).to(device)
            processor = CLIPProcessor.from_pretrained(model_path)
            return model, processor
        else:
            st.error(f"âŒ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return None, None
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜: {str(e)}")
        return None, None

def main():
    st.title("ğŸ¥ ì˜ì•½í’ˆ ë¶„ë¦¬ë°°ì¶œ AI")
    st.markdown("---")
    st.write("ì˜ì•½í’ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì¢…ë¥˜ë¥¼ ë¶„ë¥˜í•˜ê³  ì˜¬ë°”ë¥¸ ë¶„ë¦¬ë°°ì¶œ ë°©ë²•ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("ğŸ“‹ ë¶„ë¥˜ ê°€ëŠ¥í•œ ì˜ì•½í’ˆ")
        st.write("â€¢ ğŸ’Š ì•Œì•½ ë¸”ë¦¬ìŠ¤í„°íŒ©")
        st.write("â€¢ ğŸ“¦ ì•Œì•½ ë¸”ë¦¬ìŠ¤í„°íŒ© (ë°•ìŠ¤ í¬í•¨)")
        st.write("â€¢ ğŸ¼ ìœ ë¦¬ë³‘")
        st.write("â€¢ ğŸ‘ï¸ ì•ˆì•½")
        st.write("â€¢ ğŸ§´ ì—°ê³ ")

        st.header("ğŸ“– ì‚¬ìš© ë°©ë²•")
        st.write("1. ì˜ì•½í’ˆ ì‚¬ì§„ ì—…ë¡œë“œ")
        st.write("2. AI ìë™ ë¶„ì„ ëŒ€ê¸°")
        st.write("3. ë¶„ë¦¬ë°°ì¶œ ë°©ë²• í™•ì¸")
        st.warning("âš ï¸ í…ìŠ¤íŠ¸ê°€ ì„ ëª…í•˜ê²Œ ë³´ì´ë„ë¡ ì´¬ì˜í•˜ë©´ ë” ì •í™•í•œ ë¶„ë¥˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        st.header("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
        device = "GPU" if torch.cuda.is_available() else "CPU"
        st.write(f"ë””ë°”ì´ìŠ¤: {device}")

    with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        model_clip, processor_clip = load_model()

    if model_clip is None or processor_clip is None:
        st.error("ğŸš« ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ê²½ë¡œì™€ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.info("ğŸ’¡ ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    st.success("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    uploaded_file = st.file_uploader(
        "ğŸ“¸ ì˜ì•½í’ˆ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["jpg", "jpeg", "png"],
        help="JPG, JPEG, PNG í˜•ì‹ì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ ì„ ëª…í•˜ê²Œ ë³´ì´ëŠ” ì´ë¯¸ì§€ì¼ìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤."
    )

    if uploaded_file is not None:
        try:
            col1, col2 = st.columns([1, 1])

            with col1:
                st.subheader("ğŸ“· ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
                st.image(uploaded_file, caption="ë¶„ì„í•  ì´ë¯¸ì§€", use_container_width=True)

            temp_path = f"temp_{uploaded_file.name}"
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            if st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary"):
                with col2:
                    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")

                    # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text("ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
                    progress_bar.progress(20)

                    status_text.text("OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
                    progress_bar.progress(40)

                    status_text.text("í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...")
                    progress_bar.progress(50)

                    status_text.text("AI ëª¨ë¸ ì‹¤í–‰ ì¤‘...")
                    progress_bar.progress(70)

                    result = classify_and_dispose(temp_path, model_clip, processor_clip)

                    progress_bar.progress(90)
                    status_text.text("ê²°ê³¼ ìƒì„± ì¤‘...")

                    progress_bar.progress(100)
                    status_text.text("ë¶„ì„ ì™„ë£Œ!")

                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                    st.markdown(f"""
                    <div style="padding: 1rem; border-radius: 0.5rem; background-color: #e8f4fd; margin: 1rem 0; border-left: 4px solid #1f77b4;">
                        <h3>ğŸ” ìµœì¢… ë¶„ë¥˜ ê²°ê³¼: {result['final_label']}</h3>
                    </div>
                    """, unsafe_allow_html=True)

                    if result['final_confidence'] > 0.8:
                        st.success(f"ğŸ“Š ì‹ ë¢°ë„: {result['final_confidence']:.1%} (ë†’ìŒ)")
                    elif result['final_confidence'] > 0.6:
                        st.warning(f"ğŸ“Š ì‹ ë¢°ë„: {result['final_confidence']:.1%} (ë³´í†µ)")
                    else:
                        st.error(f"ğŸ“Š ì‹ ë¢°ë„: {result['final_confidence']:.1%} (ë‚®ìŒ)")
                        st.warning("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")

                    st.info(f"""â™»ï¸ **ë¶„ë¦¬ë°°ì¶œ ë°©ë²•**: {result['disposal_context']}""")

                    with st.expander("ğŸ” ë¶„ì„ ê³¼ì • ìƒì„¸ ì •ë³´", expanded=True):
                        st.markdown("### 1ï¸âƒ£ CLIP ëª¨ë¸ ì›ë³¸ ì˜ˆì¸¡")
                        st.write(f"- ì˜ˆì¸¡: **{result['original_clip_label']}**")
                        st.write(f"- ì‹ ë¢°ë„: {result['original_clip_confidence']:.1%}")

                        st.markdown("### 2ï¸âƒ£ OCR í‚¤ì›Œë“œ ë¶„ì„")
                        if result['ocr_text'] and result['ocr_confidence']:
                            st.write("**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**")
                            st.code(result['ocr_text'])
                            st.write("**OCR ê²°ê³¼ ì‹ ë¢°ë„:**")
                            st.code(result['ocr_confidence'])

                            col_k1, col_k2 = st.columns(2)
                            with col_k1:
                                st.write("**í‚¤ì›Œë“œ ì ìˆ˜:**")
                                for category, score in result['keyword_scores'].items():
                                    emoji = {"pill": "ğŸ’Š", "liquid": "ğŸ§´", "ointment": "ğŸ§´", "eye_drop": "ğŸ‘ï¸"}
                                    st.write(f"{emoji.get(category, 'â€¢')} {category}: {score}ê°œ")

                            with col_k2:
                                st.write("**ë°œê²¬ëœ í‚¤ì›Œë“œ:**")
                                for category, keywords in result['found_keywords'].items():
                                    if keywords:
                                        st.write(f"**{category}:** {', '.join(keywords)}")
                        else:
                            st.warning("OCRë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                        st.markdown("### 3ï¸âƒ£ í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •")
                        if result['logit_adjustments']:
                            st.write("**ì ìˆ˜ ì¡°ì • ë‚´ì—­:**")
                            for label, boost in result['logit_adjustments'].items():
                                st.write(f"- {label}: +{boost:.3f}")
                            st.write(f"- ì¡°ì • í›„ ì˜ˆì¸¡: **{result['adjusted_clip_label']}**")
                            st.write(f"- ì¡°ì • í›„ ì‹ ë¢°ë„: {result['adjusted_clip_confidence']:.1%}")
                        else:
                            st.write("í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •ì´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                        st.markdown("### 4ï¸âƒ£ OCR ê¸°ë°˜ ìµœì¢… ë³´ì •")
                        if result['ocr_correction_applied']:
                            st.success(f"âœ… OCR í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ '{result['final_label']}'ë¡œ ìµœì¢… ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.info("OCR ê¸°ë°˜ ì¶”ê°€ ë³´ì •ì´ ì ìš©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                        st.markdown("### ğŸ“‹ ë³€ê²½ ì‚¬í•­ ìš”ì•½")
                        changes = []
                        if result['original_clip_label'] != result['adjusted_clip_label']:
                            changes.append(f"CLIP í‚¤ì›Œë“œ ì¡°ì •: {result['original_clip_label']} â†’ {result['adjusted_clip_label']}")
                        if result['ocr_correction_applied']:
                            changes.append(f"OCR ê¸°ë°˜ ë³´ì •: {result['adjusted_clip_label']} â†’ {result['final_label']}")

                        if changes:
                            for change in changes:
                                st.write(f"â€¢ {change}")
                        else:
                            st.write("â€¢ ì›ë³¸ CLIP ì˜ˆì¸¡ì´ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

            if os.path.exists(temp_path):
                os.remove(temp_path)

        except Exception as e:
            st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.write("ì˜¤ë¥˜ ìƒì„¸ ì •ë³´:")
            st.code(str(e))

    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #666;'>"
        "<p>ğŸŒ± í™˜ê²½ì„ ìƒê°í•˜ëŠ” AI ê¸°ë°˜ ì˜ì•½í’ˆ ë¶„ë¦¬ë°°ì¶œ ë„ìš°ë¯¸ (í‚¤ì›Œë“œ ë¶„ì„ ì‹œê°í™” ë²„ì „)</p>"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
